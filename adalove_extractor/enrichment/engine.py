"""
Motor principal de enriquecimento de dados.

Orquestra todos os processos de enriquecimento:
- Normaliza√ß√£o temporal
- Detec√ß√£o de professor
- Classifica√ß√£o
- Ancoragem
- Normaliza√ß√£o de URLs
- Gera√ß√£o de hash
"""

from typing import Optional, Dict, Tuple
import logging

from .normalizer import (
    extract_date_time,
    parse_week_number,
    calculate_sprint,
    normalize_urls_pipe,
    extract_data_hora_components,
    is_sincrono,
    detect_known_names,
)
from .anchor import AnchorEngine
from ..utils.hash import compute_hash


class EnrichmentEngine:
    """
    Motor de enriquecimento que transforma cards brutos em cards enriquecidos.
    
    Adiciona campos derivados aos campos b√°sicos extra√≠dos:
    - Normaliza√ß√£o temporal (semana_num, sprint, data_hora_iso, etc.)
    - Detec√ß√£o de professor (com fallback heur√≠stico)
    - Classifica√ß√£o baseada em card_type (nova taxonomia)
    - Ancoragem de autoestudos √†s instru√ß√µes
    - Normaliza√ß√£o de URLs
    - Hash de integridade
    
    NOTA: Usa nova taxonomia (card_type, is_avaliativo) como prim√°ria,
    mantendo campos legados (is_autoestudo, is_instrucao) para compatibilidade.
    """
    
    def __init__(
        self, 
        logger: Optional[logging.Logger] = None,
        previous_anchors: Optional[Dict[str, Tuple[str, str]]] = None
    ):
        """
        Inicializa o motor de enriquecimento.
        
        Args:
            logger: Logger para registrar processo (opcional)
            previous_anchors: Ancoragens anteriores a preservar
        """
        self.logger = logger or logging.getLogger(__name__)
        self.anchor_engine = AnchorEngine(previous_anchors)
    
    def enrich_cards(self, cards_data: list[dict]) -> list[dict]:
        """
        Enriquece uma lista de cards com todos os campos derivados.
        
        Args:
            cards_data: Lista de dicion√°rios com dados brutos dos cards
            
        Returns:
            Lista de dicion√°rios com campos enriquecidos
        """
        self.logger.info("üîß Enriquecendo registros (ancoragem robusta, normaliza√ß√µes)...")
        
        # Faz c√≥pia para n√£o modificar originais
        enriched = [dict(card) for card in cards_data]
        
        # 1. Detec√ß√£o de nomes conhecidos (primeira passagem)
        known_names = detect_known_names(enriched)
        
        # 2. Enriquecimento individual de cada card
        for card in enriched:
            self._enrich_single_card(card, known_names)
        
        # 3. Ancoragem (requer todos os cards enriquecidos)
        enriched = self.anchor_engine.anchor_autoestudos(enriched, self.logger)
        
        return enriched
    
    def _enrich_single_card(self, card: dict, known_names: list[str]) -> None:
        """
        Enriquece um card individual com campos derivados.
        
        Modifica o dicion√°rio in-place.
        
        Args:
            card: Dicion√°rio do card a enriquecer
            known_names: Lista de nomes frequentes detectados
            
        Deprecated Fields:
            Campos legados mantidos para compatibilidade (ser√£o removidos em v4.0):
            - is_autoestudo: Use card_type == "autoestudo"
            - is_instrucao: Use card_type in ["encontro_orientacao", "encontro_instrucao"]
            - is_atividade_ponderada: Use is_avaliativo
        """
        # === Normaliza√ß√£o temporal ===
        card["semana_num"] = parse_week_number(card.get("semana"))
        card["sprint"] = calculate_sprint(card["semana_num"])
        
        # Extrai data/hora do texto combinado
        combined_text = "\n".join([
            card.get("titulo") or "",
            card.get("descricao") or "",
            card.get("texto_completo") or ""
        ])
        iso, date_str, time_str = extract_date_time(combined_text)
        
        # Logging quando fallback de data/hora √© usado
        if not card.get("data_hora") and iso:
            self.logger.debug(f"   üìÖ Fallback data/hora: {date_str} {time_str} (extra√≠do do texto)")
        
        card["data_hora_iso"] = iso
        card["data_ddmmaaaa"] = date_str
        card["hora_hhmm"] = time_str
        
        # === Detec√ß√£o de professor ===
        # Professor j√° foi extra√≠do no card.py, apenas manter compatibilidade
        if not card.get("professor"):
            # Fallback para detec√ß√£o heur√≠stica se n√£o foi extra√≠do
            fallback_prof = self._guess_professor_fallback(
                card.get("texto_completo") or "", 
                known_names
            )
            if fallback_prof:
                self.logger.debug(f"   üë®‚Äçüè´ Fallback professor: {fallback_prof}")
                card["professor"] = fallback_prof
        
        # === Classifica√ß√£o j√° foi feita deterministicamente no card.py ===
        # Apenas garantir que os campos est√£o presentes
        card_type = card.get("card_type", "outros")
        is_encontro = card.get("is_encontro", False)
        is_sincrono = card.get("is_sincrono", False)
        is_avaliativo = card.get("is_avaliativo", False)
        
        # Manter campos legados por compatibilidade (DEPRECATED em v4.0)
        card["is_autoestudo"] = (card_type == "autoestudo")
        card["is_instrucao"] = is_encontro
        card["is_atividade_ponderada"] = is_avaliativo
        
        # Warning de deprecia√ß√£o (log apenas 1x por execu√ß√£o)
        if not hasattr(self, '_deprecation_warned'):
            self.logger.warning(
                "‚ö†Ô∏è  DEPRECIA√á√ÉO: Campos 'is_autoestudo', 'is_instrucao', 'is_atividade_ponderada' "
                "ser√£o removidos em v4.0. Use 'card_type' e 'is_avaliativo'."
            )
            self._deprecation_warned = True
        
        self.logger.debug(f"   üè∑Ô∏è Tipo: {card_type} | Encontro: {is_encontro} | S√≠ncrono: {is_sincrono} | Avaliativo: {is_avaliativo}")
        
        # === Normaliza√ß√£o de URLs ===
        links_normalized = normalize_urls_pipe(card.get("links") or "")
        materiais_normalized = normalize_urls_pipe(card.get("materiais") or "")
        arquivos_normalized = normalize_urls_pipe(card.get("arquivos") or "")
        
        card["links_urls"] = " | ".join(links_normalized) if links_normalized else ""
        card["materiais_urls"] = " | ".join(materiais_normalized) if materiais_normalized else ""
        card["arquivos_urls"] = " | ".join(arquivos_normalized) if arquivos_normalized else ""
        
        card["num_links"] = len(links_normalized)
        card["num_materiais"] = len(materiais_normalized)
        card["num_arquivos"] = len(arquivos_normalized)
        
        # === Hash de integridade ===
        card["record_hash"] = compute_hash(
            card.get("titulo"),
            card.get("data_ddmmaaaa"),
            card.get("professor")
        )

    def _guess_professor_fallback(self, texto: str, known_names: list[str]) -> str:
        """
        Fallback para detec√ß√£o heur√≠stica de professor.
        Usado apenas quando professor n√£o foi extra√≠do deterministicamente.
        """
        import re
        
        # Regex para nome completo
        name_pattern = re.compile(
            r"^[A-Z√Å√Ç√É√Ä√â√ä√ç√ì√î√ï√ö√á][A-Za-z√Å√Ç√É√Ä√â√ä√ç√ì√î√ï√ö√á√§√¢√£√†√©√™√≠√≥√¥√µ√∫√ß'`¬¥^~.-]+"
            r"(\s+[A-Z√Å√Ç√É√Ä√â√ä√ç√ì√î√ï√ö√á][A-Za-z√Å√Ç√É√Ä√â√ä√ç√ì√î√ï√ö√á√§√¢√£√†√©√™√≠√≥√¥√µ√∫√ß'`¬¥^~.-]+){1,}$"
        )
        
        for line in texto.splitlines():
            line = line.strip()
            if name_pattern.match(line) and line in known_names:
                return line
        
        return ""







